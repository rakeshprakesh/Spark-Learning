package com.internal.cloudteens

import org.apache.spark.{SparkConf, SparkContext}

object HellBella {
  def main(args: Array[String]): Unit = {
    val sparkConf = new SparkConf()
    sparkConf.setAppName("Hella Bella")
    sparkConf.setMaster("local")
    val sc = new SparkContext(sparkConf)
    val rdd1 = sc.textFile("/Spark/connections") // Reading Input File
    val rdd2 = rdd1.map(x => (x.split(",")(2).toInt, x.split(",")(3).toInt)) // (23,340)
    val rdd3 = rdd2.map(x => (x._1, (x._2, 1))) // (23,(340,1))
    val rdd4 = rdd3.reduceByKey((x, y) => (x._1 + y._1, x._2 + y._2)) // (23,(600,4))
    val rdd5 = rdd4.map(x => (x._1, x._2._1 / x._2._2)) // (23,150)
    rdd5.foreach(println)
  }
}


===============

Input Data Set

1,person1,23,340
2,person2,23,440
3,person3,23,120
4,person4,23,330
1,person1,24,340
2,person2,24,440
3,person3,24,120
4,person4,24,330
1,person1,25,340
2,person2,25,440
3,person3,25,120
4,person4,25,330
1,person1,26,340
2,person2,26,440
3,person3,26,120
4,person4,26,330
1,person1,27,340
2,person2,27,440
3,person3,27,120
4,person4,27,330
1,person1,29,340
2,person2,29,440
3,person3,29,120
4,person4,29,330
1,person1,30,340
2,person2,30,440
3,person3,30,120
4,person4,30,330
